{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e4232bf19fe4499aa6c61dd35c97cbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fb01b2d57c2e409b9c866914466384dc",
              "IPY_MODEL_00732b74dd1e49e1a60951533921b9c2",
              "IPY_MODEL_8004de3acda34b24ad7118d746c8ae48"
            ],
            "layout": "IPY_MODEL_ce25b85ec9724341bc5370702201b75d"
          }
        },
        "fb01b2d57c2e409b9c866914466384dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4b3ba6859f46019012125e61b29eca",
            "placeholder": "​",
            "style": "IPY_MODEL_73050feb785a44788c8998c07b9c9fc5",
            "value": "model.safetensors: 100%"
          }
        },
        "00732b74dd1e49e1a60951533921b9c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96a42c54a1fa49598960865cfaf0e2c7",
            "max": 178675806,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d03ba742c894e6483434193101edcdc",
            "value": 178675806
          }
        },
        "8004de3acda34b24ad7118d746c8ae48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aee861e7c6c849dfab5d2009008bc297",
            "placeholder": "​",
            "style": "IPY_MODEL_42173c80ac204abcb1d26d42ee9fbb2c",
            "value": " 179M/179M [00:00&lt;00:00, 245MB/s]"
          }
        },
        "ce25b85ec9724341bc5370702201b75d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4b3ba6859f46019012125e61b29eca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "73050feb785a44788c8998c07b9c9fc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96a42c54a1fa49598960865cfaf0e2c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d03ba742c894e6483434193101edcdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aee861e7c6c849dfab5d2009008bc297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42173c80ac204abcb1d26d42ee9fbb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q timm albumentations==1.4.3 torchmetrics\n",
        "\n",
        "import os, glob, random\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PMyJVXSTmEQM",
        "outputId": "aead835f-36a4-43cb-8332-13619fa9dc60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/137.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.0/137.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.9/981.9 kB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m113.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m39.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m107.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/dataset_colores.zip -d /content/dataset_color"
      ],
      "metadata": {
        "id": "QM3VsCNvfsLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT = Path('/content/dataset_color/dataset_colores_clasificados_v2')\n",
        "PARTS = ['upper', 'lower']\n",
        "COLORS = sorted([p.name for p in (ROOT / PARTS[0]).iterdir() if p.is_dir()])  # 12 colores\n",
        "\n",
        "def build_paths_labels(root):\n",
        "    paths, labels = [], []\n",
        "    for part in PARTS:\n",
        "        for color in COLORS:\n",
        "            for img in glob.glob(str(root / part / color / '*')):\n",
        "                paths.append(img)\n",
        "                labels.append(COLORS.index(color))\n",
        "    return np.array(paths), np.array(labels)\n",
        "\n",
        "paths, labels = build_paths_labels(ROOT)\n",
        "print('Total imágenes:', len(paths))\n",
        "print('Distribución por clase:', Counter(labels))\n",
        "num_classes = len(COLORS)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxS6LEk6mE1d",
        "outputId": "53b1607e-8f40-4c47-dd75-8be27aeab298"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total imágenes: 9274\n",
            "Distribución por clase: Counter({np.int64(9): 2075, np.int64(3): 2037, np.int64(8): 1559, np.int64(1): 731, np.int64(4): 700, np.int64(11): 394, np.int64(5): 356, np.int64(2): 342, np.int64(10): 330, np.int64(7): 309, np.int64(0): 285, np.int64(6): 156})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "train_idx, val_idx = next(skf.split(paths, labels))  # primera fold\n",
        "train_paths, val_paths = paths[train_idx], paths[val_idx]\n",
        "train_labels, val_labels = labels[train_idx], labels[val_idx]\n"
      ],
      "metadata": {
        "id": "X3AZAbjLmJD6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SIZE = 224\n",
        "\n",
        "train_tf = A.Compose([\n",
        "    A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
        "    A.HorizontalFlip(p=0.5),\n",
        "    A.ShiftScaleRotate(shift_limit=0.08, scale_limit=0.15, rotate_limit=20, p=0.8, border_mode=0),\n",
        "    A.Perspective(scale=(0.02, 0.05), p=0.3),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.08, contrast_limit=0.08, p=0.2),  # leve\n",
        "    A.GaussianBlur(blur_limit=3, p=0.1),\n",
        "    A.ISONoise(p=0.1),\n",
        "    A.CoarseDropout(max_holes=8, max_height=IMG_SIZE//10, max_width=IMG_SIZE//10, p=0.5),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "val_tf = A.Compose([\n",
        "    A.Resize(IMG_SIZE, IMG_SIZE),\n",
        "    A.Normalize(mean=(0.485,0.456,0.406), std=(0.229,0.224,0.225)),\n",
        "    ToTensorV2(),\n",
        "])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3hROp7YmKvn",
        "outputId": "2a9eb652-454e-4f35-abf6-cc0b05ef3d1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-7-3185104030.py:4: DeprecationWarning: Initializing with 'size' as an integer and a separate 'width' is deprecated. Please use a tuple (height, width) for the 'size' argument.\n",
            "  A.RandomResizedCrop(IMG_SIZE, IMG_SIZE, scale=(0.6, 1.0), ratio=(0.8, 1.2)),\n",
            "/usr/local/lib/python3.11/dist-packages/albumentations/augmentations/blur/transforms.py:190: UserWarning: blur_limit and sigma_limit minimum value can not be both equal to 0. blur_limit minimum value changed to 3.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ColorDataset(Dataset):\n",
        "    def __init__(self, paths, labels, tfm):\n",
        "        self.paths = paths\n",
        "        self.labels = labels\n",
        "        self.tfm = tfm\n",
        "    def __len__(self):\n",
        "        return len(self.paths)\n",
        "    def __getitem__(self, i):\n",
        "        img = np.array(Image.open(self.paths[i]).convert('RGB'))\n",
        "        img = self.tfm(image=img)['image']\n",
        "        return img, int(self.labels[i])\n",
        "\n",
        "train_ds = ColorDataset(train_paths, train_labels, train_tf)\n",
        "val_ds   = ColorDataset(val_paths, val_labels, val_tf)\n"
      ],
      "metadata": {
        "id": "GAdEomYSmLZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pesos por clase inversamente proporcionales a su frecuencia\n",
        "class_counts = np.bincount(train_labels, minlength=num_classes)\n",
        "class_weights = 1.0 / (class_counts + 1e-6)\n",
        "sample_weights = class_weights[train_labels]\n",
        "sampler = WeightedRandomSampler(sample_weights, num_samples=len(sample_weights), replacement=True)\n",
        "\n",
        "BATCH_SIZE = 512\n",
        "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, sampler=sampler, num_workers=2, pin_memory=True)\n",
        "val_dl   = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# Para la loss\n",
        "class_weights_t = torch.tensor(class_weights, dtype=torch.float32)\n"
      ],
      "metadata": {
        "id": "6KBl4d7fmNUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "model = timm.create_model('resnet101', pretrained=True, num_classes=num_classes)\n",
        "# Warm-up: congelamos todas menos la FC\n",
        "for name, p in model.named_parameters():\n",
        "    if 'fc' not in name:\n",
        "        p.requires_grad = False\n",
        "model.to(device)\n",
        "\n",
        "# pérdida (elige UNA)\n",
        "use_focal = False\n",
        "if use_focal:\n",
        "    # Focal Loss simple\n",
        "    class FocalLoss(nn.Module):\n",
        "        def __init__(self, alpha=None, gamma=2.0):\n",
        "            super().__init__()\n",
        "            self.alpha = alpha\n",
        "            self.gamma = gamma\n",
        "        def forward(self, logits, targets):\n",
        "            ce = nn.functional.cross_entropy(logits, targets, weight=self.alpha, reduction='none')\n",
        "            pt = torch.exp(-ce)\n",
        "            loss = ((1 - pt) ** self.gamma) * ce\n",
        "            return loss.mean()\n",
        "    criterion = FocalLoss(alpha=class_weights_t.to(device), gamma=2.0)\n",
        "else:\n",
        "    criterion = nn.CrossEntropyLoss(weight=class_weights_t.to(device), label_smoothing=0.05)\n",
        "\n",
        "optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()),\n",
        "                              lr=3e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=10)\n"
      ],
      "metadata": {
        "id": "aBvuw0MWmQ0O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "e4232bf19fe4499aa6c61dd35c97cbb3",
            "fb01b2d57c2e409b9c866914466384dc",
            "00732b74dd1e49e1a60951533921b9c2",
            "8004de3acda34b24ad7118d746c8ae48",
            "ce25b85ec9724341bc5370702201b75d",
            "df4b3ba6859f46019012125e61b29eca",
            "73050feb785a44788c8998c07b9c9fc5",
            "96a42c54a1fa49598960865cfaf0e2c7",
            "3d03ba742c894e6483434193101edcdc",
            "aee861e7c6c849dfab5d2009008bc297",
            "42173c80ac204abcb1d26d42ee9fbb2c"
          ]
        },
        "outputId": "55621878-b633-4c08-b56e-1e80abe35355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/179M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e4232bf19fe4499aa6c61dd35c97cbb3"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchmetrics.classification import MulticlassF1Score, MulticlassAccuracy\n",
        "import torch.nn.functional as F\n",
        "from tqdm import tqdm\n",
        "\n",
        "def run_epoch(dl, train=True):\n",
        "    model.train(train)\n",
        "    loss_sum, n = 0.0, 0\n",
        "    f1 = MulticlassF1Score(num_classes=num_classes, average='macro').to(device)\n",
        "    acc = MulticlassAccuracy(num_classes=num_classes, average='macro').to(device)\n",
        "\n",
        "    for x, y in tqdm(dl, disable=False):\n",
        "        x, y = x.to(device), y.to(device)\n",
        "        with torch.set_grad_enabled(train):\n",
        "            logits = model(x)\n",
        "            loss = criterion(logits, y)\n",
        "        if train:\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        loss_sum += loss.item() * x.size(0)\n",
        "        n += x.size(0)\n",
        "        f1.update(logits, y)\n",
        "        acc.update(logits, y)\n",
        "\n",
        "    return loss_sum / n, f1.compute().item(), acc.compute().item()\n",
        "\n",
        "best_f1 = 0\n",
        "EPOCHS_WARM = 3\n",
        "EPOCHS_FT = 20\n",
        "\n",
        "print('--- Warm-up (solo la cabeza) ---')\n",
        "for epoch in range(EPOCHS_WARM):\n",
        "    tr_loss, tr_f1, tr_acc = run_epoch(train_dl, True)\n",
        "    va_loss, va_f1, va_acc = run_epoch(val_dl, False)\n",
        "    scheduler.step()\n",
        "    print(f\"[W{epoch+1}] train loss {tr_loss:.4f} f1 {tr_f1:.3f}  | val loss {va_loss:.4f} f1 {va_f1:.3f}\")\n",
        "\n",
        "# Unfreeze para fine‑tuning completo\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS_FT)\n",
        "\n",
        "print('--- Fine-tuning ---')\n",
        "patience, patience_cnt = 5, 0\n",
        "for epoch in range(EPOCHS_FT):\n",
        "    tr_loss, tr_f1, tr_acc = run_epoch(train_dl, True)\n",
        "    va_loss, va_f1, va_acc = run_epoch(val_dl, False)\n",
        "    scheduler.step()\n",
        "    print(f\"[{epoch+1}] train loss {tr_loss:.4f} f1 {tr_f1:.3f} | val loss {va_loss:.4f} f1 {va_f1:.3f}\")\n",
        "\n",
        "    if va_f1 > best_f1:\n",
        "        best_f1 = va_f1\n",
        "        patience_cnt = 0\n",
        "        torch.save(model.state_dict(), 'best_resnet101_color.pth')\n",
        "    else:\n",
        "        patience_cnt += 1\n",
        "        if patience_cnt >= patience:\n",
        "            print(\"Early stopping\")\n",
        "            break\n",
        "\n",
        "print(\"Best macro-F1:\", best_f1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc_Ow3drmSUC",
        "outputId": "19cef8c6-f08e-42f7-ad61-27f92e3986df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Warm-up (solo la cabeza) ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:17<00:00, 13.08it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W1] train loss 2.2909 f1 0.016  | val loss 3.1058 f1 0.010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:16<00:00, 13.73it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.55it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W2] train loss 2.2135 f1 0.069  | val loss 3.1714 f1 0.054\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:16<00:00, 13.90it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.41it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[W3] train loss 2.1293 f1 0.083  | val loss 3.1878 f1 0.020\n",
            "--- Fine-tuning ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.59it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1] train loss 1.8373 f1 0.188 | val loss 3.0298 f1 0.231\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.59it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2] train loss 1.1250 f1 0.433 | val loss 2.2944 f1 0.397\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.54it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3] train loss 0.8700 f1 0.571 | val loss 2.0787 f1 0.476\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[4] train loss 0.7732 f1 0.650 | val loss 1.8545 f1 0.573\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5] train loss 0.7027 f1 0.708 | val loss 1.7587 f1 0.614\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6] train loss 0.6540 f1 0.729 | val loss 1.6998 f1 0.639\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[7] train loss 0.6118 f1 0.764 | val loss 1.6938 f1 0.638\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8] train loss 0.5798 f1 0.770 | val loss 1.7081 f1 0.642\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9] train loss 0.5702 f1 0.789 | val loss 1.6679 f1 0.655\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[10] train loss 0.5296 f1 0.808 | val loss 1.5215 f1 0.702\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11] train loss 0.5277 f1 0.805 | val loss 1.5696 f1 0.691\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.04it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[12] train loss 0.4872 f1 0.832 | val loss 1.5202 f1 0.705\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[13] train loss 0.4867 f1 0.830 | val loss 1.5026 f1 0.713\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[14] train loss 0.4899 f1 0.832 | val loss 1.4973 f1 0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[15] train loss 0.4694 f1 0.846 | val loss 1.5275 f1 0.704\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.06it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16] train loss 0.4703 f1 0.840 | val loss 1.5098 f1 0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[17] train loss 0.4761 f1 0.841 | val loss 1.4710 f1 0.723\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:51<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[18] train loss 0.4661 f1 0.851 | val loss 1.4954 f1 0.718\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[19] train loss 0.4630 f1 0.850 | val loss 1.4880 f1 0.722\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 232/232 [00:50<00:00,  4.55it/s]\n",
            "100%|██████████| 58/58 [00:03<00:00, 15.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[20] train loss 0.4733 f1 0.841 | val loss 1.4633 f1 0.724\n",
            "Best macro-F1: 0.7235713005065918\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Guardar el modelo en Google Drive para inferencia\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os, torch, json, datetime\n",
        "\n",
        "# === Configura tu ruta en Drive ===\n",
        "SAVE_DIR = \"/content/drive/MyDrive/color_classifier\"  # cámbialo si quieres\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Asegúrate de tener estas variables en el entorno (del entrenamiento):\n",
        "# - model          -> tu red ya entrenada\n",
        "# - num_classes    -> número de clases (12)\n",
        "# - COLORS         -> lista con los nombres de las clases\n",
        "# - IMG_SIZE       -> tamaño de entrada usado (p.ej. 224)\n",
        "\n",
        "# Pasa el modelo a CPU y eval antes de guardar\n",
        "model.eval()\n",
        "model.cpu()\n",
        "\n",
        "timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "ckpt_path = os.path.join(SAVE_DIR, f\"resnet101_color_best_{timestamp}.pth\")\n",
        "\n",
        "torch.save({\n",
        "    \"model_name\": \"resnet101\",\n",
        "    \"state_dict\": model.state_dict(),\n",
        "    \"num_classes\": num_classes,\n",
        "    \"class_names\": COLORS,\n",
        "    \"img_size\": IMG_SIZE,\n",
        "    \"mean\": (0.485, 0.456, 0.406),\n",
        "    \"std\":  (0.229, 0.224, 0.225),\n",
        "}, ckpt_path)\n",
        "\n",
        "print(\"✔️ Checkpoint guardado en:\", ckpt_path)\n",
        "\n",
        "# (Opcional) exportar también una versión TorchScript para inferencia más simple\n",
        "try:\n",
        "    example = torch.randn(1, 3, IMG_SIZE, IMG_SIZE)\n",
        "    scripted = torch.jit.trace(model, example)\n",
        "    ts_path = os.path.join(SAVE_DIR, f\"resnet101_color_scripted_{timestamp}.pt\")\n",
        "    scripted.save(ts_path)\n",
        "    print(\"✔️ TorchScript guardado en:\", ts_path)\n",
        "except Exception as e:\n",
        "    print(\"No se generó TorchScript (opcional). Error:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Q6AiI0Je85s",
        "outputId": "c5220f89-a704-490b-f077-3b770543b400"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "✔️ Checkpoint guardado en: /content/drive/MyDrive/color_classifier/resnet101_color_best_20250725_075421.pth\n",
            "✔️ TorchScript guardado en: /content/drive/MyDrive/color_classifier/resnet101_color_scripted_20250725_075421.pt\n"
          ]
        }
      ]
    }
  ]
}