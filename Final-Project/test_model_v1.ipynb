{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# INFERENCIA EN VIDEO:\n",
        "#   - YOLOv8 detecta personas\n",
        "#   - Se recorta upper/lower por persona\n",
        "#   - ResNet101 (tu clasificador) predice color para cada crop\n",
        "#   - Se genera un video anotado con \"Sup:\" y \"Inf:\"\n",
        "# ============================================================\n",
        "\n",
        "!pip install -q timm albumentations==1.4.3 ultralytics opencv-python tqdm\n",
        "\n",
        "import os\n",
        "import cv2\n",
        "import time\n",
        "import torch\n",
        "import timm\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "from ultralytics import YOLO\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1) Montar Drive y configurar rutas\n",
        "# ------------------------------------------------------------\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CKPT_PATH  = \"/content/drive/MyDrive/color_classifier/resnet101_color_best_20250725_075421.pth\"  # <- ajusta\n",
        "VIDEO_PATH = \"/content/test_video_v1.mp4\"                                          # <- ajusta\n",
        "OUT_PATH   = \"/content/test_video_result.mp4\"\n",
        "\n",
        "YOLO_WEIGHTS = \"yolov8s.pt\"\n",
        "UPPER_END_RATIO   = 0.55\n",
        "LOWER_START_RATIO = 0.45\n",
        "CONF_PERSON = 0.3\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2) Cargar el clasificador\n",
        "# ------------------------------------------------------------\n",
        "def load_color_classifier(ckpt_path: str):\n",
        "    ckpt = torch.load(ckpt_path, map_location=device)\n",
        "\n",
        "    model_name   = ckpt[\"model_name\"]\n",
        "    num_classes  = ckpt[\"num_classes\"]\n",
        "    class_names  = ckpt[\"class_names\"]\n",
        "    img_size     = ckpt[\"img_size\"]\n",
        "    mean         = ckpt.get(\"mean\", (0.485, 0.456, 0.406))\n",
        "    std          = ckpt.get(\"std\",  (0.229, 0.224, 0.225))\n",
        "\n",
        "    model = timm.create_model(model_name, pretrained=False, num_classes=num_classes)\n",
        "    model.load_state_dict(ckpt[\"state_dict\"])\n",
        "    model.eval().to(device)\n",
        "\n",
        "    tfm = A.Compose([\n",
        "        A.Resize(img_size, img_size),\n",
        "        A.Normalize(mean=mean, std=std),\n",
        "        ToTensorV2(),\n",
        "    ])\n",
        "    return model, class_names, tfm\n",
        "\n",
        "model, CLASS_NAMES, infer_tf = load_color_classifier(CKPT_PATH)\n",
        "print(\"Clases:\", CLASS_NAMES)\n",
        "\n",
        "def classify_color(img_bgr):\n",
        "    img_rgb = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2RGB)\n",
        "    x = infer_tf(image=img_rgb)['image'].unsqueeze(0).to(device)\n",
        "    with torch.no_grad():\n",
        "        logits = model(x)\n",
        "        probs = torch.softmax(logits, dim=-1)[0].cpu().numpy()\n",
        "    idx = int(np.argmax(probs))\n",
        "    return CLASS_NAMES[idx], float(probs[idx])\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3) YOLO personas\n",
        "# ------------------------------------------------------------\n",
        "yolo = YOLO(YOLO_WEIGHTS)\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4) Video\n",
        "# ------------------------------------------------------------\n",
        "cap = cv2.VideoCapture(VIDEO_PATH)\n",
        "if not cap.isOpened():\n",
        "    raise FileNotFoundError(f\"No puedo abrir el video: {VIDEO_PATH}\")\n",
        "\n",
        "width  = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "fps    = cap.get(cv2.CAP_PROP_FPS)\n",
        "total  = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "out    = cv2.VideoWriter(OUT_PATH, fourcc, fps if fps > 0 else 25, (width, height))\n",
        "\n",
        "print(f\"Video: {width}x{height} @ {fps:.2f}fps | frames: {total}\")\n",
        "\n",
        "pbar = tqdm(total=total, desc=\"Procesando video\", unit=\"frame\")\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    results = yolo.predict(frame, conf=CONF_PERSON, classes=[0], verbose=False)\n",
        "    r = results[0]\n",
        "    boxes = r.boxes.xyxy.cpu().numpy().astype(int) if r.boxes is not None else []\n",
        "\n",
        "    for box in boxes:\n",
        "        x1, y1, x2, y2 = box.tolist()\n",
        "        w, h = x2 - x1, y2 - y1\n",
        "        if w <= 0 or h <= 0:\n",
        "            continue\n",
        "\n",
        "        upper_end   = y1 + int(h * UPPER_END_RATIO)\n",
        "        lower_start = y1 + int(h * LOWER_START_RATIO)\n",
        "\n",
        "        upper_crop = frame[max(y1,0):min(upper_end,height), max(x1,0):min(x2,width)]\n",
        "        lower_crop = frame[max(lower_start,0):min(y2,height), max(x1,0):min(x2,width)]\n",
        "\n",
        "        sup_label, sup_prob = (\"NA\", 0.0)\n",
        "        inf_label, inf_prob = (\"NA\", 0.0)\n",
        "\n",
        "        if upper_crop.size > 0:\n",
        "            sup_label, sup_prob = classify_color(upper_crop)\n",
        "        if lower_crop.size > 0:\n",
        "            inf_label, inf_prob = classify_color(lower_crop)\n",
        "\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0,255,0), 2)\n",
        "\n",
        "        txt_sup = f\"Sup: {sup_label} ({sup_prob:.2f})\"\n",
        "        txt_inf = f\"Inf: {inf_label} ({inf_prob:.2f})\"\n",
        "        y_txt = max(y1 - 10, 0)\n",
        "        cv2.putText(frame, txt_sup, (x1, y_txt), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2, cv2.LINE_AA)\n",
        "        cv2.putText(frame, txt_inf, (x1, y_txt - 22 if y_txt-22>0 else y_txt + 22),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0,255,255), 2, cv2.LINE_AA)\n",
        "\n",
        "    out.write(frame)\n",
        "    pbar.update(1)\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "pbar.close()\n",
        "print(\"✅ Video procesado y guardado en:\", OUT_PATH)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIIogKwvlusX",
        "outputId": "d4b344ff-c982-439d-c2c8-a8407bef9613"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Device: cuda\n",
            "Clases: ['amarillo', 'azul', 'beige', 'blanco', 'gris', 'marron', 'morado', 'naranja', 'negro', 'rojo', 'rosa', 'verde']\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 164MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video: 1920x1080 @ 25.00fps | frames: 221\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Procesando video: 100%|██████████| 221/221 [01:28<00:00,  2.49frame/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Video procesado y guardado en: /content/test_video_result.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}